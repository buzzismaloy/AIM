# Импорт библиотек
import numpy as np

# Входные данные
x = np.array([0.66, 0.73, 0.91])  # Входной вектор
d = np.array([0.31, 0.75, 0.98, 0.51])  # Желаемые выходы
v = 0.8  # Коэффициент обучения
T = -0.5  # Порог функции активации
alpha = 1.0  # Коэффициент сигмоиды

# Исходные веса (включая пороговые коэффициенты w0j)
W = np.array([
    [-0.85,  0.12,  0.53,  0.86],  # Пороговые коэффициенты (w0)
    [-0.25,  0.57,  0.33, -0.4],   # Веса для x1 (w1j)
    [-0.09, -0.39, -0.06, -0.33],  # Веса для x2 (w2j)
    [ 0.7,   0.19,  0.17, -0.11]   # Веса для x3 (w3j)
])

# Функция активации (сигмоидная)
def sigmoid(net, alpha, T):
    return 1 / (1 + np.exp(-alpha * (net - T)))

# 1. Исходные состояния net_j
net = W[0] + W[1] * x[0] + W[2] * x[1] + W[3] * x[2]

# 2. Исходные выходы y_j
y = sigmoid(net, alpha, T)

# 3. Ошибки e_j
e = d - y

# 4. Средняя абсолютная ошибка до коррекции
MAE_before = np.mean(np.abs(e))

# 5. Обновление весов по правилу Уидроу-Хоффа
W_new = W.copy()
W_new[1:] += v * np.outer(x, e)  # Обновляем веса для x1, x2, x3
W_new[0] += v * e  # Обновляем пороговые коэффициенты

# 6. Новые состояния net_j после обновления весов
net_new = W_new[0] + W_new[1] * x[0] + W_new[2] * x[1] + W_new[3] * x[2]

# 7. Новые выходы y_j после обновления весов
y_new = sigmoid(net_new, alpha, T)

# 8. Новые ошибки e_j
e_new = d - y_new

# 9. Средняя абсолютная ошибка после коррекции
MAE_after = np.mean(np.abs(e_new))

# 10. Вывод результатов
results = {
    "Исходные состояния net_j": net,
    "Исходные выходы y": y,
    "Исходные ошибки e": e,
    "MAE до коррекции": MAE_before,
    "Обновленные веса W": W_new,
    "Новые состояния net_j": net_new,
    "Новые выходы y": y_new,
    "Новые ошибки e": e_new,
    "MAE после коррекции": MAE_after,
    "Изменение MAE": MAE_after - MAE_before
}

print(results)
